# Environment Variables Template
# Copy this file to .env and fill in your values

# Data directories
DATA_DIR=./data
INCOMING_DIR=./incoming
TEMP_DIR=./temp

# Database
DATABASE_PATH=./jobs.db

# Processing settings
MAX_WORK_EXPERIENCE=50
BATCH_SIZE=1000

# Export settings
EXPORT_DIR=./data/processed

# ============================================================================
# AI Analysis Configuration (Phase 2)
# ============================================================================

# Google Gemini API Key (for direct API calls)
# Get your key from: https://makersuite.google.com/app/apikey
# Used by: scripts/analyze_narratives.py, pages/7_AI_Analysis.py
GEMINI_API_KEY=your_gemini_api_key_here

# Google Cloud Project (for Vertex AI + BigQuery)
# Used by: scripts/deploy_vertex_ai.sh, BigQuery remote models
GCP_PROJECT_ID=your-gcp-project-id
GCP_REGION=us-central1

# BigQuery Configuration
BIGQUERY_DATASET=devpost_ai
BIGQUERY_BUCKET=your-project-id-devpost-data

# AI Model Configuration
AI_MODEL=gemini-1.5-flash
AI_TEMPERATURE=0.1
AI_MAX_OUTPUT_TOKENS=1024
AI_CONFIDENCE_THRESHOLD=0.6
